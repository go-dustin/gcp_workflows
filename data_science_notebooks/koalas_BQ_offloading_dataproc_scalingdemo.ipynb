{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "import databricks.koalas as ks\nfrom pyspark.sql import SparkSession\n\nimport datetime"}, {"cell_type": "markdown", "metadata": {}, "source": "## create the Spark session to distribute processing across a cluster"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "spark = SparkSession.builder \\\n                    .appName('Jupyter BigQuery Storage')\\\n                    .config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar') \\\n                    .getOrCreate()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Cluster update function will allow us to add & remove nodes to/from the cluster"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "def data_proc_update_cluster(project_id, region, cluster_name, service_account_json, non_preemptibile, preemptibile):\n    from google.cloud import dataproc_v1 as dataproc\n    from google.oauth2 import service_account\n\n    api_endpoint = {\"api_endpoint\": f\"{region}-dataproc.googleapis.com:443\"}\n    \n    \n    credentials = service_account.Credentials.from_service_account_file(service_account_json)\n    \n    client = dataproc.ClusterControllerClient(credentials=credentials,\n                                              client_options=api_endpoint)\n\n    cluster = client.get_cluster(project_id=project_id, \n                                 region=region, \n                                 cluster_name=cluster_name)\n\n    mask = { \"paths\": {\"config.worker_config.num_instances\": str(non_preemptibile),\n                       \"config.secondary_worker_config.num_instances\": str(preemptibile),\n\n                      }\n           }\n\n    cluster.config.worker_config.num_instances = non_preemptibile # Must update the cluster info itself\n    cluster.config.secondary_worker_config.num_instances = preemptibile \n\n    operation = client.update_cluster(project_id=project_id, \n                                      region=region, \n                                      cluster=cluster,\n                                      cluster_name=cluster_name,\n                                      update_mask=mask)\n\n    return operation.result()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Extract data from BigQuery into a Spark dataframe"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "table = '`fh-bigquery.reddit_comments.2019_12`'\ntable = \"dustinspark.demos.reddit_comments\"\n\nsp_df = spark.read \\\n             .format(\"bigquery\") \\\n             .option(\"table\", table) \\\n             .option('viewsEnabled', True) \\\n             .load()"}, {"cell_type": "markdown", "metadata": {}, "source": "## If you want to preview data you can use the toPandas() function\nBe sure to limit the number of records before pulling in to Pandas or you can exceed memory\n"}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [{"data": {"text/plain": "6738684849"}, "execution_count": 34, "metadata": {}, "output_type": "execute_result"}], "source": "row_count = sp_df.count()\nprint(f'{row_count:,} rows in the data frame')"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&amp;gt;There is no rape in Ck2\\n\\n'Because she is...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Take the ship channel tour - it's free, and ki...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I never get my youth back now :'(</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>It's for the reasons I stated.  If you feel th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What an honor! :D\\n\\nIt was a bit weird to dri...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Also shouldn't it be step 1 cut and grill the ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Yeah, as far as I've been able to tell, the fo...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>HOW DO THE ROPES AFFECT THIS MATCH??</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>/r/titlegore</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Hot Topic Guy - https://www.reddit.com/r/funko...</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                                                body\n0  &gt;There is no rape in Ck2\\n\\n'Because she is...\n1  Take the ship channel tour - it's free, and ki...\n2                  I never get my youth back now :'(\n3  It's for the reasons I stated.  If you feel th...\n4  What an honor! :D\\n\\nIt was a bit weird to dri...\n5  Also shouldn't it be step 1 cut and grill the ...\n6  Yeah, as far as I've been able to tell, the fo...\n7              HOW DO THE ROPES AFFECT THIS MATCH?? \n8                                       /r/titlegore\n9  Hot Topic Guy - https://www.reddit.com/r/funko..."}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "sp_df.limit(10).toPandas()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Create a Koalas dataframe from the Spark dataframe\n It's very easy to change between a Spark, Koalas & Pandas dataframe\n \n Be mindful when using Pandas as that will pull all the data in to the master and could exceed memory"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "koalas_df = ks.DataFrame(sp_df)\n# koala_to_spark_df = koalas_df.to_spark()\n# spark_to_pandas_df = sp_df.toPandas()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Most of the Pandas API is availble with Koalas\nIn this example you can see how easy it is to work with user defined functions (UDFs) "}, {"cell_type": "raw", "metadata": {}, "source": "def txt_splitter(text):\n    if text != None:\n        return text.split(' ')\n    else:\n        return None\n    \ntext = 'Animal Services Office'\n\ntxt_splitter(text)\n\nkoalas_df['body_2'] = koalas_df['body'].apply(txt_splitter)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Process some data using 64 CPUs and save it to a GCS bucket"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Pandas dataframe ran for 9487 seconds / 158 minutes\n"}], "source": "start = datetime.datetime.now()\nkoalas_df['body_2'] = koalas_df['body'].str.split(' ')\nkoalas_df['string_length'] = koalas_df['body'].str.len()\nkoalas_df['body_lower'] = koalas_df['body'].str.lower()\n\nkoala_to_spark_df = koalas_df.to_spark()\n\nkoala_to_spark_df.write.format(\"parquet\").option(\"path\", \"gs://dusty-study/koalas_run_1\").save() # save() is what triggers the DAG to execute\n\nend = datetime.datetime.now()\nrun_time = end - start\nrt_secs = round(run_time.total_seconds())\nrt_mins = round(rt_secs / 60)\nprint(f'64 Core dataframe ran for {rt_secs} seconds / {rt_mins} minutes')"}, {"cell_type": "markdown", "metadata": {}, "source": "## Let's scale up the cluster 980 CPUs to increase performance\nPreemptibile instances are 40% of the cost of a non-preemptiable one\n\n## Costs\n\nhttps://cloud.google.com/products/calculator#id=0ad8bb87-2d0d-446c-8533-9fee94cb677d\n\n1   x Master\n\n2   x Workers non-preemptable\n\n980 x Workers preemptable\n\n1 Hour\n\n$79.09\n\n\n### VERSUS\n\nhttps://cloud.google.com/products/calculator#id=409ff1ba-8e54-4ede-9f5e-f999e19988b8\n\n1   x Master\n\n982 x Workers non-preemptable\n\n\n1 Hour\n\n$226.09\n\n## SAVINGS\n\n### **$147**\n\n## total run cost for 980 premeptable CPUs at \\\\$1.33  per minute for 20 minutes = \\\\$26.5 "}, {"cell_type": "code", "execution_count": 37, "metadata": {}, "outputs": [], "source": "non_preemptibile = 2\npreemptibile = round(980 / 4)\nservice_account_json = '/home/dustinwilliams/dataproc-jupyter-srvc-acct.json'\nusername = 'dustinwilliams'\nproject_id = 'dusty-study'\nregion = 'us-central1'\ncluster_name = 'koalas'\ntotal_cpus = (non_preemptibile + preemptibile) * 4\n\nstart = datetime.datetime.now()\n\nupdate_result = data_proc_update_cluster(project_id, region, cluster_name, service_account_json, non_preemptibile, preemptibile)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/usr/lib/spark/python/pyspark/sql/pandas/functions.py:383: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n  warnings.warn(\n"}, {"name": "stdout", "output_type": "stream", "text": "CPU times: user 288 ms, sys: 105 ms, total: 394 ms\nWall time: 18min 32s\n"}], "source": "%%time\nkoalas_df['word_array']    = koalas_df['body'].str.split(' ')\nkoalas_df['string_length'] = koalas_df['body'].str.len()\nkoalas_df['body_lower']    = koalas_df['body'].str.lower()\n\nkoala_to_spark_df = koalas_df.to_spark()\n\nkoala_to_spark_df.write.format(\"parquet\").option(\"path\", \"gs://dusty-study/koalas_run_2\").save() "}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "DataProc cluster scaled up to 988 CPUs and ran for 1210 seconds / 20 minutes\n"}], "source": "non_preemptibile = 2\npreemptibile = 0\n\nupdate_result = data_proc_update_cluster(project_id, region, cluster_name, service_account_json, non_preemptibile, preemptibile)\n\n\nend = datetime.datetime.now()\nrun_time = end - start\nrt_secs = round(run_time.total_seconds())\nrt_mins = round(rt_secs / 60)\nprint(f'DataProc cluster scaled up to {total_cpus} CPUs and ran for {rt_secs} seconds / {rt_mins} minutes')"}, {"cell_type": "markdown", "metadata": {}, "source": "## Bigquery can be used to offload processing\n\non demand pricing\n### 1TB = $5\n\nSlot reservations can reduce this even more"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "start = datetime.datetime.now()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>", "text/plain": "Empty DataFrame\nColumns: []\nIndex: []"}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": "%%bigquery \n\nCREATE OR REPLACE TABLE `dusty-study.temp.koalas_demo`\nAS \nSELECT  body, \n        SPLIT(body, ' ')        AS word_array,\n        CHARACTER_LENGTH(body)  AS string_length,\n        LOWER(body)             AS body_lower \nFROM    dustinspark.demos.reddit_comments"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Bigquery query ran for 615 seconds / 10 minutes\n"}], "source": "end = datetime.datetime.now()\nrun_time = end - start\nrt_secs = round(run_time.total_seconds())\nrt_mins = round(rt_secs / 60)\nprint(f'Bigquery query ran for {rt_secs} seconds / {rt_mins} minutes')"}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>", "text/plain": "Empty DataFrame\nColumns: []\nIndex: []"}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": "%%bigquery\n\nCREATE OR REPLACE MODEL `temp.bqml_example`\nOPTIONS(model_type='logistic_reg') AS\nSELECT  IF(totals.transactions IS NULL, 0, 1) AS label,\n        IFNULL(device.operatingSystem, \"\") AS os,\n        device.isMobile AS is_mobile,\n        IFNULL(geoNetwork.country, \"\") AS country,\n        IFNULL(totals.pageviews, 0) AS pageviews\nFROM   `bigquery-public-data.google_analytics_sample.ga_sessions_*`"}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [], "source": "%%bigquery bqml_df_eval\n\nSELECT  *\nFROM    ML.EVALUATE(MODEL `temp.bqml_example`, \n          (SELECT  IF(totals.transactions IS NULL, 0, 1)  AS label,\n                   IFNULL(device.operatingSystem, \"\")     AS os,\n                   device.isMobile                        AS is_mobile,\n                   IFNULL(geoNetwork.country, \"\")         AS country,\n                   IFNULL(totals.pageviews, 0)            AS pageviews\n           FROM   `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n           LIMIT 10000))"}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>accuracy</th>\n      <th>f1_score</th>\n      <th>log_loss</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.5</td>\n      <td>0.141176</td>\n      <td>0.9915</td>\n      <td>0.220183</td>\n      <td>0.030425</td>\n      <td>0.980737</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   precision    recall  accuracy  f1_score  log_loss   roc_auc\n0        0.5  0.141176    0.9915  0.220183  0.030425  0.980737"}, "execution_count": 25, "metadata": {}, "output_type": "execute_result"}], "source": "bqml_df_eval.head()"}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [], "source": "%%bigquery bqml_predictions\n\nWITH ga_data AS (\nSELECT  IFNULL(device.operatingSystem, \"\")  AS os,\n        device.isMobile                     AS is_mobile,\n        IFNULL(totals.pageviews, 0)         AS pageviews,\n        IFNULL(geoNetwork.country, \"\")      AS country\nFROM    `bigquery-public-data.google_analytics_sample.ga_sessions_*`)\n\nSELECT  country,\n        SUM(predicted_label) AS total_predicted_purchases\nFROM    ML.PREDICT(MODEL `temp.bqml_example`, TABLE ga_data)\nGROUP BY country\nORDER BY total_predicted_purchases DESC\n"}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>total_predicted_purchases</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>United States</td>\n      <td>3548</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Canada</td>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Venezuela</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Japan</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Taiwan</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "         country  total_predicted_purchases\n0  United States                       3548\n1         Canada                         94\n2      Venezuela                         60\n3          Japan                         34\n4         Taiwan                         30"}, "execution_count": 27, "metadata": {}, "output_type": "execute_result"}], "source": "bqml_predictions.head()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.6"}}, "nbformat": 4, "nbformat_minor": 4}